{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "class CF(object):\n",
    "    \"\"\"docstring for CF\"\"\"\n",
    "\n",
    "    def __init__(self, Y_data, k, dist_func=cosine_similarity, uuCF=1):\n",
    "        self.uuCF = uuCF  # user-user (1) or item-item (0) CF\n",
    "        self.Y_data = Y_data if uuCF else Y_data[:, [1, 0, 2]]\n",
    "        self.k = k\n",
    "        self.dist_func = dist_func\n",
    "        self.Ybar_data = None\n",
    "        # number of users and items. Remember to add 1 since id starts from 0\n",
    "        self.n_users = int(np.max(self.Y_data[:, 0])) + 1\n",
    "        self.n_items = int(np.max(self.Y_data[:, 1])) + 1\n",
    "\n",
    "    def add(self, new_data):\n",
    "        \"\"\"\n",
    "        Update Y_data matrix when new ratings come.\n",
    "        For simplicity, suppose that there is no new user or item.\n",
    "        \"\"\"\n",
    "        self.Y_data = np.concatenate((self.Y_data, new_data), axis=0)\n",
    "\n",
    "    def normalize_Y(self):\n",
    "        users = self.Y_data[:, 0]  # all users - first col of the Y_data\n",
    "        self.Ybar_data = self.Y_data.copy()\n",
    "        self.mu = np.zeros((self.n_users,))\n",
    "        for n in range(self.n_users):\n",
    "            # row indices of rating done by user n\n",
    "            # since indices need to be integers, we need to convert\n",
    "            ids = np.where(users == n)[0].astype(np.int32)\n",
    "            # indices of all ratings associated with user n\n",
    "            item_ids = self.Y_data[ids, 1]\n",
    "            # and the corresponding ratings\n",
    "            ratings = self.Y_data[ids, 2]\n",
    "            # take mean\n",
    "            m = np.mean(ratings)\n",
    "            if np.isnan(m):\n",
    "                m = 0  # to avoid empty array and nan value\n",
    "            self.mu[n] = m\n",
    "            # normalize\n",
    "            self.Ybar_data[ids, 2] = ratings - self.mu[n]\n",
    "\n",
    "        ################################################\n",
    "        # form the rating matrix as a sparse matrix. Sparsity is important\n",
    "        # for both memory and computing efficiency. For example, if #user = 1M,\n",
    "        # #item = 100k, then shape of the rating matrix would be (100k, 1M),\n",
    "        # you may not have enough memory to store this. Then, instead, we store\n",
    "        # nonzeros only, and, of course, their locations.\n",
    "        self.Ybar = sparse.coo_matrix((self.Ybar_data[:, 2],\n",
    "                                       (self.Ybar_data[:, 1], self.Ybar_data[:, 0])), (self.n_items, self.n_users))\n",
    "        self.Ybar = self.Ybar.tocsr()\n",
    "\n",
    "    def similarity(self):\n",
    "        eps = 1e-6\n",
    "        self.S = self.dist_func(self.Ybar.T, self.Ybar.T)\n",
    "\n",
    "    def refresh(self):\n",
    "        \"\"\"\n",
    "        Normalize data and calculate similarity matrix again (after\n",
    "        some few ratings added)\n",
    "        \"\"\"\n",
    "        self.normalize_Y()\n",
    "        self.similarity()\n",
    "\n",
    "    def fit(self):\n",
    "        self.refresh()\n",
    "\n",
    "    def __pred(self, u, i, normalized=1):\n",
    "        \"\"\"\n",
    "        predict the rating of user u for item i (normalized)\n",
    "        if you need the un\n",
    "        \"\"\"\n",
    "        # Step 1: find all users who rated i\n",
    "        ids = np.where(self.Y_data[:, 1] == i)[0].astype(np.int32)\n",
    "        # Step 2:\n",
    "        users_rated_i = (self.Y_data[ids, 0]).astype(np.int32)\n",
    "        # Step 3: find similarity btw the current user and others\n",
    "        # who already rated i\n",
    "        sim = self.S[u, users_rated_i]\n",
    "        # Step 4: find the k most similarity users\n",
    "        a = np.argsort(sim)[-self.k:]\n",
    "        # and the corresponding similarity levels\n",
    "        nearest_s = sim[a]\n",
    "        # How did each of 'near' users rated item i\n",
    "        r = self.Ybar[i, users_rated_i[a]]\n",
    "        if normalized:\n",
    "            # add a small number, for instance, 1e-8, to avoid dividing by 0\n",
    "            return (r*nearest_s)[0]/(np.abs(nearest_s).sum() + 1e-8)\n",
    "\n",
    "        return (r*nearest_s)[0]/(np.abs(nearest_s).sum() + 1e-8) + self.mu[u]\n",
    "\n",
    "    def pred(self, u, i, normalized=1):\n",
    "        \"\"\"\n",
    "        predict the rating of user u for item i (normalized)\n",
    "        if you need the un\n",
    "        \"\"\"\n",
    "        if self.uuCF:\n",
    "            return self.__pred(u, i, normalized)\n",
    "        return self.__pred(i, u, normalized)\n",
    "\n",
    "    def recommend(self, u):\n",
    "        \"\"\"\n",
    "        Determine all items should be recommended for user u.\n",
    "        The decision is made based on all i such that:\n",
    "        self.pred(u, i) > 0. Suppose we are considering items which\n",
    "        have not been rated by u yet.\n",
    "        \"\"\"\n",
    "        ids = np.where(self.Y_data[:, 0] == u)[0]\n",
    "        items_rated_by_u = self.Y_data[ids, 1].tolist()\n",
    "        recommended_items = []\n",
    "        for i in range(self.n_items):\n",
    "            if i not in items_rated_by_u:\n",
    "                rating = self.__pred(u, i)\n",
    "                if rating > 0:\n",
    "                    recommended_items.append(i)\n",
    "\n",
    "        return recommended_items\n",
    "\n",
    "    def recommend2(self, u):\n",
    "        \"\"\"\n",
    "        Determine all items should be recommended for user u.\n",
    "        The decision is made based on all i such that:\n",
    "        self.pred(u, i) > 0. Suppose we are considering items which\n",
    "        have not been rated by u yet.\n",
    "        \"\"\"\n",
    "        ids = np.where(self.Y_data[:, 0] == u)[0]\n",
    "        items_rated_by_u = self.Y_data[ids, 1].tolist()\n",
    "        recommended_items = []\n",
    "\n",
    "        for i in range(self.n_items):\n",
    "            if i not in items_rated_by_u:\n",
    "                rating = self.__pred(u, i)\n",
    "                if rating > 0:\n",
    "                    recommended_items.append(i)\n",
    "\n",
    "        return recommended_items\n",
    "\n",
    "    def print_recommendation(self):\n",
    "        \"\"\"\n",
    "        print all items which should be recommended for each user\n",
    "        \"\"\"\n",
    "        print('Recommendation: ')\n",
    "        for u in range(self.n_users):\n",
    "            recommended_items = self.recommend(u)\n",
    "            if self.uuCF:\n",
    "                print('Recommend item(s):', recommended_items, 'for user', u)\n",
    "            else:\n",
    "                print('Recommend item', u, 'for user(s) : ', recommended_items)\n",
    "\n",
    "    def print_recommendation2(self ,x):\n",
    "        \"\"\"\n",
    "        print all items which should be recommended for each user\n",
    "        \"\"\"\n",
    "        print('Recommendation: ')\n",
    "        recommended_items = self.recommend(x)\n",
    "        if self.uuCF:\n",
    "            print('Recommend item(s):', recommended_items, 'for user', x)\n",
    "        else:\n",
    "            print('Recommend item', x, 'for user(s) : ', recommended_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   530   1196      5]\n",
      " [   452   1953      4]\n",
      " [    30   2159      2]\n",
      " ...\n",
      " [   529   3712      4]\n",
      " [    15    110      3]\n",
      " [   152    185    1.5]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "np.set_printoptions(formatter={'float': \"{:6.11g}\".format})\n",
    "\n",
    "\n",
    "rating = pd.read_csv('../BaseContent/input/ratings_small - Copy.csv')\n",
    "\n",
    "rating = rating.drop(columns='timestamp')\n",
    "rating_train, rating_test = train_test_split(\n",
    "    rating, test_size=0.15, random_state=42)\n",
    "\n",
    "\n",
    "train_set = rating_train.values\n",
    "test_set = rating_test.values\n",
    "\n",
    "# r_cols = ['user_id', 'item_id', 'rating']\n",
    "# ratings = pd.read_csv('../BaseContent/ml-100k/ex.dat', sep = ' ', names = r_cols, encoding='latin-1')\n",
    "\n",
    "# print(ratings.values)\n",
    "print(train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "def store_model(model, model_name=\"\"):\n",
    "    # NOTE: sklearn.joblib faster than pickle of Python\n",
    "    # INFO: can store only ONE object in a file\n",
    "    if model_name == \"\":\n",
    "        model_name = type(model).__name__\n",
    "    joblib.dump(model, '../Collaberative/model_users/' + model_name + '_model.pkl')\n",
    "\n",
    "\n",
    "def load_model(model_name):\n",
    "    # Load objects into memory\n",
    "    #del model\n",
    "    model = joblib.load('../Collaberative/model_users/' + model_name + '_model.pkl')\n",
    "    # print(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\University\\UIT-VNUHCM\\Project2\\Flask\\.env\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\Documents\\University\\UIT-VNUHCM\\Project2\\Flask\\.env\\Lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "User-user CF, RMSE = 0.9463091058560089\n"
     ]
    }
   ],
   "source": [
    "rs = CF(train_set, k=30, uuCF=1)\n",
    "rs.fit()\n",
    "store_model(rs)\n",
    "# rs.print_recommendation2(1)\n",
    "print(type(test_set))\n",
    "train_set = train_set.astype(int)\n",
    "n_tests = test_set.shape[0]\n",
    "SE = 0  # squared error\n",
    "for n in range(n_tests):\n",
    "    pred = rs.pred(test_set[n, 0], test_set[n, 1], normalized=0)\n",
    "    SE += (pred - test_set[n, 2])**2\n",
    "\n",
    "RMSE = np.sqrt(SE/n_tests)\n",
    "print('User-user CF, RMSE =', RMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.CF object at 0x00000170544C19D0>\n",
      "[1, 3, 6, 11, 13, 15, 16, 17, 20, 21, 24, 28, 29, 30, 32, 36, 37, 38, 39, 42, 45, 46, 47, 50, 55, 60, 62, 64, 72, 74, 77, 78, 81, 82, 83, 84, 85, 92, 93, 94, 96, 99, 101, 102, 103, 104, 108, 110, 111, 121, 123, 125, 130, 146, 149, 150, 152, 155, 157, 159, 163, 165, 166, 169, 171, 175, 178, 179, 181, 183, 184, 189, 190, 193, 199, 200, 206, 207, 219, 223, 227, 228, 232, 235, 236, 245, 246, 247, 250, 253, 258, 259, 260, 261, 262, 265, 275, 276, 278, 287, 288, 291, 293, 296, 299, 300, 302, 305, 306, 307, 312, 314, 318, 326, 331, 332, 337, 339, 341, 345, 346, 347, 348, 349, 353, 356, 360, 361, 363, 364, 366, 372, 373, 374, 375, 378, 380, 382, 383, 384, 387, 390, 391, 408, 409, 414, 418, 421, 422, 427, 429, 431, 437, 441, 442, 445, 447, 449, 450, 451, 452, 453, 455, 457, 458, 464, 465, 466, 468, 469, 470, 471, 473, 480, 483, 487, 488, 494, 495, 496, 497, 498, 502, 505, 506, 509, 510, 511, 515, 516, 517, 518, 519, 521, 524, 527, 528, 529, 532, 533, 537, 541, 542, 543, 546, 550, 551, 553, 555, 556, 558, 564, 567, 569, 571, 574, 581, 585, 588, 589, 590, 593, 599, 600, 606, 608, 610, 611, 612, 616, 619, 620, 621, 626, 630, 631, 633, 635, 638, 647, 653, 661, 662, 663, 664, 678, 679, 688, 700, 709, 711, 715, 718, 722, 728, 731, 737, 745, 750, 754, 757, 759, 761, 779, 782, 785, 787, 799, 800, 803, 805, 824, 830, 833, 835, 838, 839, 840, 841, 845, 846, 848, 850, 858, 866, 870, 875, 879, 881, 886, 893, 899, 901, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 917, 919, 920, 922, 923, 924, 926, 930, 932, 936, 937, 938, 943, 945, 946, 947, 949, 950, 951, 952, 953, 955, 956, 963, 964, 966, 968, 969, 971, 982, 986, 987, 988, 992, 1007, 1008, 1009, 1010, 1012, 1013, 1014, 1016, 1017, 1023, 1024, 1025, 1028, 1030, 1033, 1034, 1035, 1036, 1040, 1041, 1059, 1060, 1063, 1064, 1068, 1069, 1078, 1079, 1080, 1081, 1082, 1084, 1086, 1088, 1089, 1090, 1091, 1093, 1095, 1096, 1097, 1099, 1100, 1103, 1104, 1111, 1124, 1126, 1127, 1128, 1130, 1132, 1135, 1136, 1145, 1151, 1161, 1167, 1169, 1171, 1172, 1173, 1176, 1178, 1183, 1187, 1189, 1190, 1191, 1192, 1193, 1196, 1197, 1198, 1199, 1200, 1201, 1203, 1204, 1206, 1207, 1208, 1209, 1210, 1211, 1213, 1214, 1217, 1219, 1220, 1221, 1222, 1223, 1225, 1226, 1228, 1230, 1233, 1234, 1237, 1240, 1241, 1244, 1246, 1247, 1249, 1250, 1252, 1255, 1256, 1257, 1258, 1259, 1260, 1262, 1264, 1265, 1268, 1269, 1270, 1272, 1276, 1278, 1281, 1284, 1285, 1288, 1291, 1295, 1296, 1297, 1298, 1302, 1304, 1306, 1307, 1310, 1312, 1323, 1326, 1327, 1328, 1333, 1334, 1335, 1337, 1344, 1345, 1346, 1348, 1349, 1351, 1352, 1353, 1356, 1357, 1358, 1359, 1361, 1365, 1366, 1367, 1372, 1373, 1374, 1376, 1378, 1379, 1380, 1381, 1387, 1388, 1389, 1390, 1393, 1394, 1397, 1398, 1407, 1408, 1409, 1415, 1423, 1425, 1430, 1432, 1437, 1440, 1441, 1456, 1457, 1461, 1463, 1465, 1472, 1475, 1476, 1479, 1480, 1482, 1483, 1484, 1485, 1490, 1493, 1499, 1501, 1504, 1515, 1516, 1517, 1518, 1526, 1527, 1529, 1531, 1532, 1543, 1545, 1554, 1556, 1570, 1573, 1580, 1581, 1584, 1587, 1588, 1591, 1592, 1593, 1594, 1595, 1596, 1598, 1599, 1602, 1605, 1606, 1608, 1610, 1613, 1617, 1619, 1621, 1623, 1625, 1626, 1627, 1629, 1632, 1635, 1639, 1642, 1644, 1646, 1647, 1652, 1653, 1660, 1661, 1667, 1669, 1670, 1671, 1672, 1673, 1674, 1676, 1681, 1682, 1683, 1684, 1688, 1689, 1699, 1701, 1702, 1704, 1707, 1719, 1722, 1727, 1728, 1729, 1730, 1732, 1734, 1752, 1753, 1755, 1756, 1757, 1760, 1771, 1772, 1788, 1792, 1794, 1799, 1804, 1809, 1812, 1816, 1821, 1827, 1833, 1834, 1835, 1836, 1837, 1839, 1840, 1845, 1846, 1848, 1852, 1855, 1856, 1858, 1859, 1862, 1863, 1864, 1866, 1873, 1874, 1880, 1884, 1886, 1887, 1888, 1894, 1895, 1897, 1900, 1902, 1904, 1907, 1909, 1913, 1923, 1928, 1932, 1933, 1934, 1935, 1937, 1938, 1941, 1942, 1943, 1945, 1946, 1947, 1951, 1952, 1954, 1956, 1959, 1960, 1961, 1962, 1963, 1968, 1969, 1974, 1976, 1977, 1978, 1979, 1981, 1982, 1983, 1984, 1986, 1987, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 2004, 2009, 2010, 2013, 2014, 2015, 2017, 2019, 2021, 2022, 2023, 2025, 2026, 2029, 2038, 2039, 2040, 2041, 2043, 2044, 2047, 2052, 2053, 2055, 2056, 2058, 2062, 2064, 2065, 2066, 2067, 2068, 2073, 2076, 2078, 2079, 2080, 2084, 2085, 2087, 2092, 2094, 2095, 2097, 2098, 2102, 2108, 2109, 2111, 2112, 2115, 2116, 2117, 2118, 2119, 2121, 2123, 2124, 2125, 2133, 2134, 2136, 2138, 2141, 2144, 2145, 2146, 2148, 2153, 2154, 2159, 2160, 2163, 2164, 2165, 2166, 2170, 2176, 2182, 2184, 2186, 2187, 2188, 2189, 2194, 2200, 2203, 2205, 2206, 2207, 2214, 2215, 2236, 2241, 2244, 2246, 2248, 2249, 2253, 2254, 2255, 2257, 2259, 2261, 2262, 2264, 2266, 2269, 2272, 2275, 2278, 2279, 2280, 2283, 2284, 2285, 2286, 2287, 2289, 2290, 2291, 2295, 2297, 2302, 2303, 2304, 2306, 2316, 2318, 2322, 2324, 2325, 2327, 2329, 2330, 2331, 2333, 2334, 2335, 2337, 2342, 2345, 2346, 2347, 2348, 2349, 2355, 2360, 2361, 2362, 2365, 2367, 2368, 2369, 2371, 2372, 2375, 2376, 2379, 2380, 2382, 2383, 2389, 2391, 2393, 2395, 2396, 2397, 2399, 2400, 2401, 2402, 2403, 2404, 2406, 2407, 2411, 2412, 2413, 2414, 2419, 2420, 2422, 2423, 2429, 2434, 2435, 2440, 2441, 2442, 2443, 2446, 2447, 2450, 2451, 2453, 2456, 2457, 2461, 2463, 2465, 2467, 2468, 2469, 2471, 2473, 2474, 2476, 2478, 2483, 2485, 2486, 2487, 2488, 2491, 2495, 2498, 2499, 2501, 2502, 2504, 2506, 2511, 2513, 2514, 2517, 2521, 2522, 2523, 2524, 2525, 2526, 2527, 2529, 2533, 2537, 2539, 2542, 2545, 2548, 2552, 2553, 2555, 2558, 2563, 2565, 2566, 2567, 2570, 2571, 2572, 2574, 2577, 2581, 2586, 2587, 2589, 2590, 2594, 2599, 2600, 2606, 2607, 2609, 2612, 2613, 2615, 2616, 2621, 2627, 2633, 2638, 2639, 2640, 2643, 2644, 2651, 2654, 2656, 2660, 2662, 2669, 2671, 2672, 2674, 2676, 2682, 2683, 2691, 2692, 2693, 2694, 2696, 2700, 2704, 2707, 2708, 2712, 2713, 2715, 2716, 2721, 2725, 2727, 2730, 2731, 2732, 2733, 2735, 2738, 2739, 2741, 2747, 2748, 2752, 2757, 2759, 2761, 2762, 2764, 2766, 2769, 2775, 2776, 2782, 2792, 2793, 2794, 2795, 2796, 2799, 2803, 2804, 2805, 2807, 2808, 2810, 2815, 2816, 2817, 2819, 2822, 2824, 2827, 2828, 2836, 2837, 2843, 2845, 2846, 2851, 2853, 2855, 2858, 2860, 2862, 2863, 2866, 2867, 2872, 2876, 2877, 2883, 2886, 2887, 2890, 2892, 2894, 2898, 2899, 2900, 2902, 2904, 2906, 2907, 2908, 2916, 2918, 2924, 2928, 2930, 2935, 2937, 2939, 2940, 2941, 2942, 2944, 2945, 2946, 2947, 2948, 2949, 2950, 2959, 2961, 2964, 2966, 2969, 2971, 2974, 2975, 2976, 2977, 2978, 2983, 2987, 2988, 2989, 2990, 2992, 2993, 2995, 2997, 3000, 3008, 3010, 3011, 3019, 3025, 3028, 3029, 3031, 3032, 3033, 3034, 3035, 3040, 3042, 3043, 3045, 3046, 3048, 3053, 3055, 3060, 3067, 3068, 3069, 3071, 3072, 3075, 3077, 3079, 3081, 3087, 3089, 3091, 3096, 3097, 3100, 3101, 3102, 3112, 3113, 3114, 3115, 3118, 3121, 3122, 3127, 3130, 3133, 3134, 3135, 3141, 3142, 3150, 3155, 3167, 3168, 3169, 3171, 3173, 3174, 3177, 3179, 3180, 3181, 3198, 3200, 3201, 3203, 3205, 3206, 3208, 3211, 3216, 3218, 3224, 3235, 3238, 3240, 3243, 3248, 3250, 3251, 3254, 3256, 3258, 3261, 3263, 3269, 3272, 3273, 3275, 3281, 3286, 3289, 3292, 3296, 3300, 3301, 3304, 3306, 3307, 3310, 3313, 3314, 3317, 3318, 3324, 3325, 3327, 3328, 3330, 3331, 3340, 3342, 3344, 3347, 3350, 3354, 3355, 3357, 3360, 3361, 3364, 3365, 3371, 3377, 3379, 3384, 3386, 3387, 3388, 3390, 3392, 3393, 3395, 3399, 3401, 3402, 3412, 3414, 3418, 3421, 3422, 3425, 3430, 3435, 3436, 3438, 3439, 3440, 3441, 3442, 3444, 3445, 3448, 3450, 3451, 3452, 3457, 3461, 3462, 3463, 3465, 3467, 3470, 3471, 3475, 3480, 3481, 3487, 3489, 3490, 3491, 3494, 3495, 3496, 3497, 3498, 3501, 3503, 3504, 3506, 3507, 3508, 3510, 3511, 3512, 3516, 3519, 3520, 3525, 3529, 3531, 3534, 3536, 3543, 3545, 3546, 3547, 3548, 3553, 3554, 3557, 3559, 3564, 3565, 3569, 3573, 3574, 3576, 3577, 3584, 3590, 3596, 3598, 3602, 3604, 3608, 3609, 3611, 3616, 3618, 3621, 3624, 3626, 3632, 3633, 3634, 3635, 3638, 3639, 3640, 3653, 3657, 3665, 3668, 3669, 3672, 3677, 3682, 3685, 3686, 3688, 3694, 3695, 3698, 3699, 3704, 3707, 3708, 3716, 3718, 3719, 3721, 3724, 3725, 3726, 3730, 3731, 3733, 3734, 3735, 3736, 3737, 3738, 3741, 3744, 3747, 3754, 3757, 3758, 3759, 3760, 3763, 3769, 3770, 3775, 3783, 3785, 3787, 3789, 3791, 3792, 3793, 3794, 3801, 3804, 3805, 3806, 3809, 3811, 3816, 3819, 3825, 3831, 3833, 3835, 3836, 3844, 3846, 3847, 3851, 3852, 3854, 3855, 3858, 3859, 3860, 3861, 3868, 3870, 3871, 3872, 3882, 3886, 3889, 3896, 3897, 3906, 3908, 3911, 3913, 3914, 3915, 3916, 3917, 3918, 3919, 3921, 3922, 3923, 3924, 3925, 3927, 3928, 3929, 3933, 3934, 3936, 3938, 3941, 3946, 3947, 3949, 3950, 3955, 3957, 3962, 3964, 3965, 3966, 3975, 3978, 3979, 3980, 3984, 3987, 3989, 3991, 3993, 4005, 4009, 4011, 4012, 4014, 4015, 4016, 4017, 4018, 4019, 4024, 4027, 4029, 4030, 4031, 4033, 4034, 4035, 4036, 4037, 4042, 4043, 4051, 4052, 4053, 4054, 4061, 4062, 4063, 4066, 4068, 4069, 4081, 4085, 4086, 4090, 4091, 4101, 4102, 4103, 4104, 4105, 4108, 4111, 4124, 4130, 4132, 4133, 4141, 4142, 4144, 4148, 4153, 4155, 4156, 4158, 4161, 4167, 4168, 4173, 4174, 4184, 4185, 4187, 4188, 4190, 4191, 4197, 4198, 4200, 4203, 4211, 4212, 4216, 4218, 4220, 4221, 4223, 4226, 4229, 4232, 4234, 4246, 4247, 4251, 4254, 4255, 4263, 4268, 4270, 4274, 4277, 4279, 4280, 4292, 4293, 4294, 4296, 4297, 4298, 4299, 4300, 4302, 4304, 4305, 4306, 4308, 4312, 4316, 4317, 4319, 4322, 4324, 4329, 4337, 4340, 4343, 4344, 4345, 4349, 4351, 4352, 4353, 4359, 4360, 4361, 4367, 4368, 4369, 4378, 4383, 4388, 4390, 4391, 4394, 4397, 4402, 4410, 4411, 4414, 4420, 4424, 4428, 4432, 4433, 4438, 4440, 4441, 4447, 4448, 4450, 4459, 4462, 4464, 4465, 4466, 4469, 4471, 4473, 4475, 4477, 4478, 4480, 4482, 4487, 4491, 4495, 4500, 4508, 4509, 4511, 4518, 4519, 4520, 4523, 4528, 4531, 4533, 4535, 4537, 4545, 4546, 4552, 4553, 4558, 4561, 4562, 4564, 4570, 4571, 4572, 4589, 4590, 4602, 4610, 4615, 4616, 4619, 4621, 4627, 4629, 4630, 4634, 4639, 4640, 4642, 4644, 4654, 4658, 4661, 4662, 4664, 4673, 4677, 4678, 4681, 4687, 4698, 4699, 4700, 4701, 4703, 4709, 4710, 4711, 4721, 4723, 4728, 4731, 4732, 4740, 4744, 4752, 4756, 4768, 4771, 4775, 4783, 4789, 4792, 4800]\n"
     ]
    }
   ],
   "source": [
    "test = load_model(\"CF\")\n",
    "\n",
    "print(test)\n",
    "\n",
    "print(test.recommend(1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea52f0f6b1e9b734d3cd0e188ca5984c56df8f37a44c22b2275656db7cfffc8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
